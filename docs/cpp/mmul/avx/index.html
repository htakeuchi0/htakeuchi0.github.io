<!doctype html><html lang=ja-jp dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content='
  行列積の計算時間のCPU拡張命令による高速化
  #


  概要
  #

前ページ では，OpenMP を用いることで，行列積演算の実行時間が短縮できることを確認しました．
これは，直列に実行する処理を，並列に行うことで実行時間の短縮を図ったものですが，同様の効果を狙う別の方法として，SIMD (Single Instruction, Multiple Data) と呼ばれる方法があります．
これは，一つの命令を複数のデータに同時に適用することをいいます．
この方法は，CPUの拡張命令を用いて実現できます．
Intel CPU では，Intel Intrinsics API という，CPUの命令セット拡張へのアクセスができるAPIを公開しています [1]．
C++17 では，例えばヘッダファイル <immintrin.h> をインクルードすることで，AVX2 という拡張機能が使え，コンパイル時に -march=native -mavx2 というフラグを追加すると，AVX2 による命令を実行するプログラムが作成できます．
本ページでは，Intel CPU の拡張命令を用いて，SIMD により行列積演算の実行時間が短縮できることを確認します．
実験用に使ったプログラムは以下に配置しています．

https://github.com/htakeuchi0/mmul-gcc-sample


  CPU拡張命令の利用
  #

まず，実験用PCで，AVX2の命令が実行できるかを確かめます．
Ubutu 22.04.4 LTS の場合，以下のコマンドで確認ができます．
$ grep -m 1 -e "^flags" /proc/cpuinfo -e avx2
flags           : ...（略）... avx2 ...（略）...
AVX2 は 256 ビットごとの演算ができます．
倍精度浮動小数点数は 64 ビットなので，1つの拡張命令を，



  \(256/64=4\)

 個のデータに同時に適用できます．'><meta name=theme-color content="#FFFFFF"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://htakeuchi0.github.io/docs/cpp/mmul/avx/"><meta property="og:site_name" content="htakeuchi0 のノート"><meta property="og:title" content="行列積の計算時間のCPU拡張命令による高速化"><meta property="og:description" content=' 行列積の計算時間のCPU拡張命令による高速化 # 概要 # 前ページ では，OpenMP を用いることで，行列積演算の実行時間が短縮できることを確認しました．
これは，直列に実行する処理を，並列に行うことで実行時間の短縮を図ったものですが，同様の効果を狙う別の方法として，SIMD (Single Instruction, Multiple Data) と呼ばれる方法があります． これは，一つの命令を複数のデータに同時に適用することをいいます．
この方法は，CPUの拡張命令を用いて実現できます． Intel CPU では，Intel Intrinsics API という，CPUの命令セット拡張へのアクセスができるAPIを公開しています [1]．
C++17 では，例えばヘッダファイル <immintrin.h> をインクルードすることで，AVX2 という拡張機能が使え，コンパイル時に -march=native -mavx2 というフラグを追加すると，AVX2 による命令を実行するプログラムが作成できます．
本ページでは，Intel CPU の拡張命令を用いて，SIMD により行列積演算の実行時間が短縮できることを確認します．
実験用に使ったプログラムは以下に配置しています．
https://github.com/htakeuchi0/mmul-gcc-sample CPU拡張命令の利用 # まず，実験用PCで，AVX2の命令が実行できるかを確かめます． Ubutu 22.04.4 LTS の場合，以下のコマンドで確認ができます．
$ grep -m 1 -e "^flags" /proc/cpuinfo -e avx2 flags : ...（略）... avx2 ...（略）... AVX2 は 256 ビットごとの演算ができます． 倍精度浮動小数点数は 64 ビットなので，1つの拡張命令を， \(256/64=4\) 個のデータに同時に適用できます．'><meta property="og:locale" content="ja_jp"><meta property="og:type" content="article"><meta property="article:section" content="docs"><meta property="article:modified_time" content="2024-07-30T22:25:34+09:00"><title>行列積の計算時間のCPU拡張命令による高速化 | htakeuchi0 のノート</title>
<link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png type=image/x-icon><link rel=stylesheet href=/book.min.a82d7e77ceb134d151c4d7e381eeb30623fbd5a524d58c584d8716ecec0205bd.css integrity="sha256-qC1+d86xNNFRxNfjge6zBiP71aUk1YxYTYcW7OwCBb0=" crossorigin=anonymous><script async src="https://www.googletagmanager.com/gtag/js?id=G-RXNBZFC7LX"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-RXNBZFC7LX")}</script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>htakeuchi0 のノート</span></a></h2><ul><li><a href=/docs/cpp/>C++</a><ul><li><a href=/docs/cpp/env/>開発環境</a><ul><li><a href=/docs/cpp/env/make/>Makefile プロジェクト</a></li><li><a href=/docs/cpp/env/autoconf/>autoconf プロジェクト (1)</a></li><li><a href=/docs/cpp/env/autoconf2/>autoconf プロジェクト (2)</a></li><li><a href=/docs/cpp/env/autoconf3/>autoconf プロジェクト (3)</a></li><li><a href=/docs/cpp/env/autoconf4/>autoconf プロジェクト (4)</a></li><li><a href=/docs/cpp/env/cmake/>CMake プロジェクト (1)</a></li><li><a href=/docs/cpp/env/cmake2/>CMake プロジェクト (2)</a></li></ul></li><li><a href=/docs/cpp/fp/>関数ポインタ</a><ul><li><a href=/docs/cpp/fp/fp/>関数ポインタとその周辺</a></li><li><a href=/docs/cpp/fp/mfp/>メンバ関数ポインタとその周辺</a></li><li><a href=/docs/cpp/fp/stdfunc/>std::function とその周辺</a></li><li><a href=/docs/cpp/fp/fref/>関数への参照</a></li><li><a href=/docs/cpp/fp/retfp/>関数ポインタを返却する関数</a></li></ul></li><li><a href=/docs/cpp/arrp/>配列へのポインタ</a><ul><li><a href=/docs/cpp/arrp/arrp/>配列へのポインタとその周辺</a></li><li><a href=/docs/cpp/arrp/arr_ref/>配列への参照</a></li><li><a href=/docs/cpp/arrp/stdarray/>std::array について</a></li><li><a href=/docs/cpp/arrp/retarrref/>配列への参照を返却する関数</a></li></ul></li><li><a href=/docs/cpp/mmul/>行列積の計算時間</a><ul><li><a href=/docs/cpp/mmul/basic/>行列を表現するデータ構造と行列積の計算時間</a></li><li><a href=/docs/cpp/mmul/openmp/>行列積の計算時間のOpenMPによる高速化</a></li><li><a href=/docs/cpp/mmul/avx/ class=active>行列積の計算時間のCPU拡張命令による高速化</a></li></ul></li></ul></li><li><a href=/docs/math/>数学一般</a><ul><li><a href=/docs/math/exp/>指数関数の定積分</a></li><li><a href=/docs/math/optim/>数理最適化</a><ul><li><a href=/docs/math/optim/manopt/>多様体上の数理最適化</a><ul></ul></li></ul></li><li><a href=/docs/math/exp_normal/>指数関数の定積分：正規分布の累積分布関数の計算への応用</a></li><li><a href=/docs/math/stat/>数理統計</a><ul><li><a href=/docs/math/stat/dice/>サイコロの出目の確率</a><ul><li><a href=/docs/math/stat/dice/dice_basic/>サイコロを繰り返し投げる試行の確率モデル</a></li><li><a href=/docs/math/stat/dice/dice_ratio/>サイコロをN回投げたときちょうど6回に1回の割合で1の目が出る確率</a></li><li><a href=/docs/math/stat/dice/dice_approx_ratio/>サイコロをN回投げたときおよそ6回に1回程度の割合で1の目が出ることの確認</a></li><li><a href=/docs/math/stat/dice/dice_randval/>サイコロをN回投げたときおよそ6回に1回程度の割合で1の目が出ることの確率変数の導入による整理</a></li><li><a href=/docs/math/stat/dice/dice_inf/>サイコロを無限回投げる場合の確率モデル</a></li></ul></li><li><a href=/docs/math/stat/dp/>差分プライバシ</a><ul><li><a href=/docs/math/stat/dp/basic/>差分プライバシの基本</a></li></ul></li><li><a href=/docs/math/stat/lap/>ラプラス分布</a><ul><li><a href=/docs/math/stat/lap/trunclap/>ラプラス分布と切断ラプラス分布</a></li><li><a href=/docs/math/stat/lap/sampling/>ラプラス分布や切断ラプラス分布からのサンプリング</a></li><li><a href=/docs/math/stat/lap/mle/>特殊なラプラス分布や切断ラプラス分布のパラメータ推定</a></li></ul></li></ul></li><li><a href=/docs/math/year2023/>2023</a><ul><li><a href=/docs/math/year2023/year2023_2/>2023 - 実装改良編</a></li></ul></li><li><a href=/docs/math/plarail/>プラレールのある数学的定式化について</a><ul><li><a href=/docs/math/plarail/rail/>レール</a></li><li><a href=/docs/math/plarail/layout/>レイアウト</a></li><li><a href=/docs/math/plarail/plarail-problems/>プラレール問題</a></li></ul></li></ul></li><li><a href=/docs/hugo/>Hugo</a><ul><li><a href=/docs/hugo/base/>空のサイトの生成</a></li><li><a href=/docs/hugo/set_config/>ページの追加とサイトの設定</a></li><li><a href=/docs/hugo/genpages/>公開用ファイルの生成</a></li><li><a href=/docs/hugo/shortcode/>独自ショートコードの定義</a></li><li><a href=/docs/hugo/book_katex/>Book テーマの hint ショートコードブロック内に数式を表示する際の注意</a></li></ul></li><li><a href=/docs/others/>その他</a><ul><li><a href=/docs/others/pmbok/>プロジェクトマネジメント知識体系 (PMBOK) ガイドに関するノート</a></li></ul></li></ul><ul><li><a href=/#disclaimer target=_blank rel=noopener>免責事項</a></li><li><a href=/#privacy_policy target=_blank rel=noopener>プライバシーポリシー</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu>
</label><strong>行列積の計算時間のCPU拡張命令による高速化</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#概要>概要</a></li><li><a href=#cpu拡張命令の利用>CPU拡張命令の利用</a></li><li><a href=#ループ展開の利用>ループ展開の利用</a></li><li><a href=#数値実験>数値実験</a></li><li><a href=#まとめ>まとめ</a></li><li><a href=#参考文献>参考文献</a></li></ul></nav></aside></header><article class=markdown><h1 id=行列積の計算時間のcpu拡張命令による高速化>行列積の計算時間のCPU拡張命令による高速化
<a class=anchor href=#%e8%a1%8c%e5%88%97%e7%a9%8d%e3%81%ae%e8%a8%88%e7%ae%97%e6%99%82%e9%96%93%e3%81%aecpu%e6%8b%a1%e5%bc%b5%e5%91%bd%e4%bb%a4%e3%81%ab%e3%82%88%e3%82%8b%e9%ab%98%e9%80%9f%e5%8c%96>#</a></h1><h2 id=概要>概要
<a class=anchor href=#%e6%a6%82%e8%a6%81>#</a></h2><p><a href=https://htakeuchi0.github.io/docs/cpp/mmul/openmp/>前ページ</a> では，OpenMP を用いることで，行列積演算の実行時間が短縮できることを確認しました．</p><p>これは，直列に実行する処理を，並列に行うことで実行時間の短縮を図ったものですが，同様の効果を狙う別の方法として，SIMD (Single Instruction, Multiple Data) と呼ばれる方法があります．
これは，一つの命令を複数のデータに同時に適用することをいいます．</p><p>この方法は，CPUの拡張命令を用いて実現できます．
Intel CPU では，Intel Intrinsics API という，CPUの命令セット拡張へのアクセスができるAPIを公開しています <a href=#intel:1>[1]</a>．</p><p>C++17 では，例えばヘッダファイル <code>&lt;immintrin.h></code> をインクルードすることで，AVX2 という拡張機能が使え，コンパイル時に <code>-march=native -mavx2</code> というフラグを追加すると，AVX2 による命令を実行するプログラムが作成できます．</p><p>本ページでは，Intel CPU の拡張命令を用いて，SIMD により行列積演算の実行時間が短縮できることを確認します．</p><p>実験用に使ったプログラムは以下に配置しています．</p><ul><li><a href=https://github.com/htakeuchi0/mmul-gcc-sample>https://github.com/htakeuchi0/mmul-gcc-sample</a></li></ul><h2 id=cpu拡張命令の利用>CPU拡張命令の利用
<a class=anchor href=#cpu%e6%8b%a1%e5%bc%b5%e5%91%bd%e4%bb%a4%e3%81%ae%e5%88%a9%e7%94%a8>#</a></h2><p>まず，実験用PCで，AVX2の命令が実行できるかを確かめます．
Ubutu 22.04.4 LTS の場合，以下のコマンドで確認ができます．</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ grep -m <span style=color:#ae81ff>1</span> -e <span style=color:#e6db74>&#34;^flags&#34;</span> /proc/cpuinfo -e avx2
</span></span><span style=display:flex><span>flags           : ...（略）... avx2 ...（略）...
</span></span></code></pre></div><p>AVX2 は 256 ビットごとの演算ができます．
倍精度浮動小数点数は 64 ビットなので，1つの拡張命令を，
<link rel=stylesheet href=/katex/katex.min.css><script defer src=/katex/katex.min.js></script><script defer src=/katex/auto-render.min.js onload=renderMathInElement(document.body)></script><span>\(256/64=4\)
</span>個のデータに同時に適用できます．</p><p>このようなCPUの拡張命令を利用する場合，演算対象の変数を格納するアドレスが，&ldquo;キリのよい値&rdquo; である必要があります．
AVX2 の場合，そのアドレスは256ビット，つまり32バイトの倍数でなければなりません．
このような，変数のアドレスに関する制約や，その制約に合わせて変数のメモリ上の格納位置を調整をすることを <strong>アライメント</strong> と呼びます．</p><p>C++ では， <code>alignas</code> キーワードでアライメント指定ができます．</p><p>例えば，</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#66d9ef>double</span> a[const_val<span style=color:#f92672>::</span>kSize <span style=color:#f92672>*</span> const_val<span style=color:#f92672>::</span>kSize];
</span></span></code></pre></div><p>の代わりに，</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#66d9ef>alignas</span>(<span style=color:#ae81ff>32</span>) <span style=color:#66d9ef>double</span> a[const_val<span style=color:#f92672>::</span>kSize <span style=color:#f92672>*</span> const_val<span style=color:#f92672>::</span>kSize];
</span></span></code></pre></div><p>とすることで，先頭アドレスが32バイトの倍数となるよう，変数がメモリ空間上に配置されます．</p><p><code>std::array&lt;double, const_val::kSize * const_val::kSize></code> も同様に，以下のように指定できます．</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#66d9ef>alignas</span>(<span style=color:#ae81ff>32</span>) std<span style=color:#f92672>::</span>array<span style=color:#f92672>&lt;</span>doubl, const_val<span style=color:#f92672>::</span>kSize <span style=color:#f92672>*</span> const_val<span style=color:#f92672>::</span>kSize<span style=color:#f92672>&gt;</span> a;
</span></span></code></pre></div><p><code>new</code> でヒープ領域上にメモリを確保する方法や，<code>std::vector</code> を使う方法の場合，動的に確保した配列要素のアライメントを指定する手段はありそうですが，標準的な方法がわからなかったため，本ページでは省略します．</p><p>ここで，AVX2を使って，どのように行列積演算が効率化できるかを考えます．</p><p><span>\(C=AB\)
</span>とおきます．
<span>\(c^{[i,j]}=(c_{ij},c_{i+1,j},c_{i+2,j},c_{i+3,j})^T\)
</span>とします．
ただし，<span>
\(\cdot^T\)
</span>は転置作用素です．
このとき，
<span>\[\begin{aligned}
c^{[i,j]}&=\begin{pmatrix}c_{ij}\\c_{i+1,j}\\c_{i+2,j}\\c_{i+3,j}\end{pmatrix}\\
&=\begin{pmatrix}\sum_{k=0}^{n-1}a_{ik}b_{kj}\\\sum_{k=0}^{n-1}a_{i+1,k}b_{kj}\\\sum_{k=0}^{n-1}a_{i+2,k}b_{kj}\\\sum_{k=0}^{n-1}a_{i+3,k}b_{kj}\end{pmatrix}\\
&=\sum_{k=0}^{n-1}b_{kj}\begin{pmatrix}a_{ik}\\a_{i+1,k}\\a_{i+2,k}\\a_{i+3,k}\end{pmatrix}\\
&=\sum_{k=0}^{n-1}\left(\begin{pmatrix}a_{ik}\\a_{i+1,k}\\a_{i+2,k}\\a_{i+3,k}\end{pmatrix}\odot(\bm{1}_4b_{kj})\right)\\
\end{aligned}\]
</span>と表せます．
ただし，<span>
\(\bm{1}_4=(1,1,1,1)^T\)
</span>, <span>\(x\odot y\)
</span>は要素ごとの積をとる演算を表します．
<span>\(c^{[i,j]}\,(i=0,4,8,\dots,n-4,\,j=0,1,\dots,n-1)\)
</span>を計算すると <span>\(C\)
</span>のすべての要素が計算できることになりますので，以下の3つの演算が1つの拡張命令で実現できれば，<span>
\(c^{[i,j]}\)
</span>は効率的に計算できそうです．</p><ul><li><span>\(b_{kj}\mapsto \bm{1}_4b_{kj}\)</span></li><li><span>\(\left(\begin{pmatrix}x_1\\x_2\\x_3\\x_4\end{pmatrix},\begin{pmatrix}y_1\\y_2\\y_3\\y_4\end{pmatrix}\right)\mapsto \begin{pmatrix}x_1\\x_2\\x_3\\x_4\end{pmatrix}\odot\begin{pmatrix}y_1\\y_2\\y_3\\y_4\end{pmatrix}\)</span></li><li><span>\(\left(\begin{pmatrix}x_1\\x_2\\x_3\\x_4\end{pmatrix},\begin{pmatrix}y_1\\y_2\\y_3\\y_4\end{pmatrix}\right)\mapsto \begin{pmatrix}x_1\\x_2\\x_3\\x_4\end{pmatrix}+\begin{pmatrix}y_1\\y_2\\y_3\\y_4\end{pmatrix}\)</span></li></ul><p>Intel(R) Intrinsics Guide <a href=#intel:1>[1]</a> によると，これらは，<code>_mm256_broadcast_sd</code>, <code>_mm256_mul_pd</code>, <code>_mm256_add_pd</code> で実現できることがわかります．
これら，AVX2で演算するために要素を読み込む <code>_mm256_load_pd</code> と, 演算結果を指定のアドレスに書き出す <code>_mm256_store_pd</code> をあわせると，AVX2 を用いた行列積演算の実装ができるようになります．</p><p>例えば，AVX2を使わない実装が以下のとおりであるとします (<code>sdim_raw_array</code>)．</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>unsigned</span> <span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> const_val<span style=color:#f92672>::</span>kSize; i<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>unsigned</span> <span style=color:#66d9ef>int</span> j <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; j <span style=color:#f92672>&lt;</span> const_val<span style=color:#f92672>::</span>kSize; j<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>double</span><span style=color:#f92672>&amp;</span> cij <span style=color:#f92672>=</span> c_[i <span style=color:#f92672>+</span> const_val<span style=color:#f92672>::</span>kSize<span style=color:#f92672>*</span>j];
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>unsigned</span> <span style=color:#66d9ef>int</span> k <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; k <span style=color:#f92672>&lt;</span> const_val<span style=color:#f92672>::</span>kSize; k<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>      cij <span style=color:#f92672>+=</span> a_[i <span style=color:#f92672>+</span> const_val<span style=color:#f92672>::</span>kSize<span style=color:#f92672>*</span>k] <span style=color:#f92672>*</span> b_[k <span style=color:#f92672>+</span> const_val<span style=color:#f92672>::</span>kSize<span style=color:#f92672>*</span>j];
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>これを，AVX2 を利用した実装に変更すると，以下のようになります (<code>sdim_raw_array_avx</code>)．</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#66d9ef>constexpr</span> std<span style=color:#f92672>::</span>size_t kSkipNumIndices <span style=color:#f92672>=</span> <span style=color:#ae81ff>256</span> <span style=color:#f92672>/</span> <span style=color:#ae81ff>64</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>unsigned</span> <span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> const_val<span style=color:#f92672>::</span>kSize; i <span style=color:#f92672>+=</span> kSkipNumIndices) {
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>unsigned</span> <span style=color:#66d9ef>int</span> j <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; j <span style=color:#f92672>&lt;</span> const_val<span style=color:#f92672>::</span>kSize; j<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>    __m256d added <span style=color:#f92672>=</span> _mm256_load_pd(<span style=color:#f92672>&amp;</span>c_[i <span style=color:#f92672>+</span> const_val<span style=color:#f92672>::</span>kSize<span style=color:#f92672>*</span>j]);
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>unsigned</span> <span style=color:#66d9ef>int</span> k <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; k <span style=color:#f92672>&lt;</span> const_val<span style=color:#f92672>::</span>kSize; k<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>      __m256d broadcast_b <span style=color:#f92672>=</span> _mm256_broadcast_sd(<span style=color:#f92672>&amp;</span>b_[k <span style=color:#f92672>+</span> const_val<span style=color:#f92672>::</span>kSize<span style=color:#f92672>*</span>j]);
</span></span><span style=display:flex><span>      __m256d loaded_a <span style=color:#f92672>=</span> _mm256_load_pd(<span style=color:#f92672>&amp;</span>a_[i <span style=color:#f92672>+</span> const_val<span style=color:#f92672>::</span>kSize<span style=color:#f92672>*</span>k]);
</span></span><span style=display:flex><span>      __m256d multiplied <span style=color:#f92672>=</span> _mm256_mul_pd(loaded_a, broadcast_b);
</span></span><span style=display:flex><span>      added <span style=color:#f92672>=</span> _mm256_add_pd(added, multiplied);
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    _mm256_store_pd(<span style=color:#f92672>&amp;</span>c_[i <span style=color:#f92672>+</span> const_val<span style=color:#f92672>::</span>kSize<span style=color:#f92672>*</span>j], added);
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h2 id=ループ展開の利用>ループ展開の利用
<a class=anchor href=#%e3%83%ab%e3%83%bc%e3%83%97%e5%b1%95%e9%96%8b%e3%81%ae%e5%88%a9%e7%94%a8>#</a></h2><p>ところで，ループ展開という手法を使うと，さらに実行時間の短縮を図ることができます．
単にループで実現していた部分をベタ書きすることで，不要な処理が削減され，実行時間が短縮される場合があります．</p><p>4回展開する場合の実装例は以下の通りです (<code>sdim_raw_array_avx_unroll</code>)．
単に4回分のループをベタ書きしているだけです．</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#66d9ef>constexpr</span> std<span style=color:#f92672>::</span>size_t kSkipNumIndices <span style=color:#f92672>=</span> <span style=color:#ae81ff>256</span> <span style=color:#f92672>/</span> <span style=color:#ae81ff>64</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>constexpr</span> std<span style=color:#f92672>::</span>size_t kUnroll <span style=color:#f92672>=</span> <span style=color:#ae81ff>4</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>unsigned</span> <span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> const_val<span style=color:#f92672>::</span>kSize; i <span style=color:#f92672>+=</span> kSkipNumIndices<span style=color:#f92672>*</span>kUnroll) {
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>unsigned</span> <span style=color:#66d9ef>int</span> j <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; j <span style=color:#f92672>&lt;</span> const_val<span style=color:#f92672>::</span>kSize; j<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>    __m256d added0 <span style=color:#f92672>=</span> _mm256_load_pd(<span style=color:#f92672>&amp;</span>c_[i <span style=color:#f92672>+</span> const_val<span style=color:#f92672>::</span>kSize<span style=color:#f92672>*</span>j]);
</span></span><span style=display:flex><span>    __m256d added1 <span style=color:#f92672>=</span> _mm256_load_pd(<span style=color:#f92672>&amp;</span>c_[i <span style=color:#f92672>+</span> kSkipNumIndices <span style=color:#f92672>+</span> const_val<span style=color:#f92672>::</span>kSize<span style=color:#f92672>*</span>j]);
</span></span><span style=display:flex><span>    __m256d added2 <span style=color:#f92672>=</span> _mm256_load_pd(<span style=color:#f92672>&amp;</span>c_[i <span style=color:#f92672>+</span> kSkipNumIndices<span style=color:#f92672>*</span><span style=color:#ae81ff>2</span> <span style=color:#f92672>+</span> const_val<span style=color:#f92672>::</span>kSize<span style=color:#f92672>*</span>j]);
</span></span><span style=display:flex><span>    __m256d added3 <span style=color:#f92672>=</span> _mm256_load_pd(<span style=color:#f92672>&amp;</span>c_[i <span style=color:#f92672>+</span> kSkipNumIndices<span style=color:#f92672>*</span><span style=color:#ae81ff>3</span> <span style=color:#f92672>+</span> const_val<span style=color:#f92672>::</span>kSize<span style=color:#f92672>*</span>j]);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>unsigned</span> <span style=color:#66d9ef>int</span> k <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; k <span style=color:#f92672>&lt;</span> const_val<span style=color:#f92672>::</span>kSize; k<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>      __m256d broadcast_b <span style=color:#f92672>=</span> _mm256_broadcast_sd(<span style=color:#f92672>&amp;</span>b_[k <span style=color:#f92672>+</span> const_val<span style=color:#f92672>::</span>kSize<span style=color:#f92672>*</span>j]);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>      __m256d loaded_a <span style=color:#f92672>=</span> _mm256_load_pd(<span style=color:#f92672>&amp;</span>a_[i <span style=color:#f92672>+</span> const_val<span style=color:#f92672>::</span>kSize<span style=color:#f92672>*</span>k]);
</span></span><span style=display:flex><span>      __m256d multiplied <span style=color:#f92672>=</span> _mm256_mul_pd(loaded_a, broadcast_b);
</span></span><span style=display:flex><span>      added0 <span style=color:#f92672>=</span> _mm256_add_pd(added0, multiplied);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>      loaded_a <span style=color:#f92672>=</span> _mm256_load_pd(<span style=color:#f92672>&amp;</span>a_[i <span style=color:#f92672>+</span> kSkipNumIndices <span style=color:#f92672>+</span> const_val<span style=color:#f92672>::</span>kSize<span style=color:#f92672>*</span>k]);
</span></span><span style=display:flex><span>      multiplied <span style=color:#f92672>=</span> _mm256_mul_pd(loaded_a, broadcast_b);
</span></span><span style=display:flex><span>      added1 <span style=color:#f92672>=</span> _mm256_add_pd(added1, multiplied);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>      loaded_a <span style=color:#f92672>=</span> _mm256_load_pd(<span style=color:#f92672>&amp;</span>a_[i <span style=color:#f92672>+</span> kSkipNumIndices<span style=color:#f92672>*</span><span style=color:#ae81ff>2</span> <span style=color:#f92672>+</span> const_val<span style=color:#f92672>::</span>kSize<span style=color:#f92672>*</span>k]);
</span></span><span style=display:flex><span>      multiplied <span style=color:#f92672>=</span> _mm256_mul_pd(loaded_a, broadcast_b);
</span></span><span style=display:flex><span>      added2 <span style=color:#f92672>=</span> _mm256_add_pd(added2, multiplied);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>      loaded_a <span style=color:#f92672>=</span> _mm256_load_pd(<span style=color:#f92672>&amp;</span>a_[i <span style=color:#f92672>+</span> kSkipNumIndices<span style=color:#f92672>*</span><span style=color:#ae81ff>3</span> <span style=color:#f92672>+</span> const_val<span style=color:#f92672>::</span>kSize<span style=color:#f92672>*</span>k]);
</span></span><span style=display:flex><span>      multiplied <span style=color:#f92672>=</span> _mm256_mul_pd(loaded_a, broadcast_b);
</span></span><span style=display:flex><span>      added3 <span style=color:#f92672>=</span> _mm256_add_pd(added3, multiplied);
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    _mm256_store_pd(<span style=color:#f92672>&amp;</span>c_[i <span style=color:#f92672>+</span> const_val<span style=color:#f92672>::</span>kSize<span style=color:#f92672>*</span>j], added0);
</span></span><span style=display:flex><span>    _mm256_store_pd(<span style=color:#f92672>&amp;</span>c_[i <span style=color:#f92672>+</span> kSkipNumIndices <span style=color:#f92672>+</span> const_val<span style=color:#f92672>::</span>kSize<span style=color:#f92672>*</span>j], added1);
</span></span><span style=display:flex><span>    _mm256_store_pd(<span style=color:#f92672>&amp;</span>c_[i <span style=color:#f92672>+</span> kSkipNumIndices<span style=color:#f92672>*</span><span style=color:#ae81ff>2</span> <span style=color:#f92672>+</span> const_val<span style=color:#f92672>::</span>kSize<span style=color:#f92672>*</span>j], added2);
</span></span><span style=display:flex><span>    _mm256_store_pd(<span style=color:#f92672>&amp;</span>c_[i <span style=color:#f92672>+</span> kSkipNumIndices<span style=color:#f92672>*</span><span style=color:#ae81ff>3</span> <span style=color:#f92672>+</span> const_val<span style=color:#f92672>::</span>kSize<span style=color:#f92672>*</span>j], added3);
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h2 id=数値実験>数値実験
<a class=anchor href=#%e6%95%b0%e5%80%a4%e5%ae%9f%e9%a8%93>#</a></h2><p>生の1次元配列と <code>std::array</code> による1次元配列による，以下の合計6種類の方法について，前ページまでと同様の方針で，実行時間を比較します．</p><ul><li>AVX2を使わない実装 (<code>sdim_raw_array</code>, <code>sdim_std_array</code>)</li><li>AVX2を使う実装 (<code>sdim_raw_array_avx</code>, <code>sdim_std_array_avx</code>)</li><li>AVX2を使って4回ループ展開もする実装 (<code>sdim_raw_array_avx_unroll</code>, <code>sdim_std_array_avx_unroll</code>)</li></ul><p>以下に計測条件を再掲します．</p><p>実行時間は，以下の手順で計測します．</p><ol><li>行列積の演算を続けて10回行い，その開始時刻と終了時刻の差を10で割る．</li><li>その操作を100回行い，その平均値を計測結果として採用する．</li></ol><p>実行環境は以下のとおりです．</p><ul><li>CPU: 13th Gen Intel(R) Core(TM) i7-1360P (16コア)</li><li>メモリ: 16.0GiB</li><li>OS: Linux (Ubuntu 22.04.3 LTS)</li><li>コンパイラ: g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0</li></ul><p>実験結果は以下のとおりです．</p><figure class=text-center><img src=/images/docs/cpp/mmul/plot-avx.png><figcaption><h4>Figure 1. 実行結果</h4></figcaption></figure><table><thead><tr><th style=text-align:left>Elapsed Time [sec]</th><th style=text-align:left>-O0</th><th style=text-align:left>-O1</th><th style=text-align:left>-O2</th><th style=text-align:left>-O3</th></tr></thead><tbody><tr><td style=text-align:left>sdim_raw_array</td><td style=text-align:left>0.035528</td><td style=text-align:left>0.010755</td><td style=text-align:left>0.012693</td><td style=text-align:left>0.005464</td></tr><tr><td style=text-align:left>sdim_std_array</td><td style=text-align:left>0.068458</td><td style=text-align:left>0.034348</td><td style=text-align:left>0.016420</td><td style=text-align:left>0.016439</td></tr><tr><td style=text-align:left>sdim_raw_array_avx</td><td style=text-align:left>0.027181</td><td style=text-align:left>0.003242</td><td style=text-align:left>0.005019</td><td style=text-align:left>0.004688</td></tr><tr><td style=text-align:left>sdim_std_array_avx</td><td style=text-align:left>0.034000</td><td style=text-align:left>0.003193</td><td style=text-align:left>0.005014</td><td style=text-align:left>0.004673</td></tr><tr><td style=text-align:left>sdim_raw_array_avx_unroll</td><td style=text-align:left>0.017972</td><td style=text-align:left>0.001828</td><td style=text-align:left>0.002041</td><td style=text-align:left>0.002026</td></tr><tr><td style=text-align:left>sdim_std_array_avx_unroll</td><td style=text-align:left>0.026068</td><td style=text-align:left>0.001836</td><td style=text-align:left>0.001985</td><td style=text-align:left>0.001985</td></tr></tbody></table><p>最適化レベル1以上をみると，AVX2を使うと約3ミリ秒（約0.003秒），ループ展開まで使うと約2ミリ秒（約0.002秒）まで実行時間が短縮できていることがわかります．</p><p>特に，ループ展開によって実行時間がさらに短くなっていることもわかります．</p><p>最も実行時間が短かったのは，最適化レベル1の <code>sdim_raw_array_avx_unroll</code> の 0.001828 秒ですが，同じく最適化レベル1の <code>sdim_raw_array</code> は 0.010755 秒なので，AVX2 とループ展開の利用で，約 1/6 まで短縮できていることがわかります．</p><h2 id=まとめ>まとめ
<a class=anchor href=#%e3%81%be%e3%81%a8%e3%82%81>#</a></h2><p>本ページでは，Intel CPU の拡張命令を用いて，行列積演算の実行時間が短縮できることを確認しました．</p><p>その結果，生の1次元配列で表現する方式 (<code>sdim_raw_array</code>) に AVX2 およびループ展開を利用すると，そうしない場合の約1/6の実行時間となり，ほぼ2ミリ秒（0.001828 秒）まで実行時間が短縮されたことがわかりました．</p><p>したがって，Intel CPU の拡張命令を用いた，SIMDによる実行時間の短縮効果が観測できたといえます．</p><p>AVX512 やその他のCPU拡張命令による，実行時間の短縮効果の確認は今後の課題です．</p><h2 id=参考文献>参考文献
<a class=anchor href=#%e5%8f%82%e8%80%83%e6%96%87%e7%8c%ae>#</a></h2><p><a id=intel:1></a>[1] Intel，“Intel(R) Intrinsics Guide”, <a href=https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html>https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html</a>, 2024/7/5 最終アクセス．</p></article><hr><p><small><a rel=license href="https://creativecommons.org/licenses/by-nd/4.0/deed.ja?_fsi=E6fL9iEx"><img src=https://i.creativecommons.org/l/by-nd/4.0/88x31.png alt=クリエイティブ・コモンズ・ライセンス style=border-width:0></a><br>本ページは <a rel=license href="https://creativecommons.org/licenses/by-nd/4.0/deed.ja?_fsi=E6fL9iEx">クリエイティブ・コモンズ 表示 - 改変禁止 4.0 国際ライセンス (CC BY-ND 4.0)</a> の下に提供されています。</small></p><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/htakeuchi0/htakeuchi0.github.io-sources/commit/19fd7218b44b17a43b6f510777bb1b33b5c4a4b3 title='Last modified by htakeuchi0 | July 30, 2024' target=_blank rel=noopener><img src=/svg/calendar.svg class=book-icon alt=Calendar>
<span>July 30, 2024</span></a></div></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#概要>概要</a></li><li><a href=#cpu拡張命令の利用>CPU拡張命令の利用</a></li><li><a href=#ループ展開の利用>ループ展開の利用</a></li><li><a href=#数値実験>数値実験</a></li><li><a href=#まとめ>まとめ</a></li><li><a href=#参考文献>参考文献</a></li></ul></nav></div></aside></main></body></html>